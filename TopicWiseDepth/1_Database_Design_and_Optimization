1. Database Design and Optimization
Schema Design: Design a flexible and efficient database schema. Normalize data where necessary but also be mindful of performance bottlenecks that might arise from too many joins.

Indexing: Use indexes to optimize read-heavy queries. However, balance it since excessive indexing can slow down write operations.

Query Optimization: Write efficient SQL queries. Avoid N+1 query problems, use proper joins, and make sure queries are optimized for performance.

 ************************************ In-depth understanding **********************************************
 
> ‚ö†Ô∏è **Indexing:** Use indexes to optimize read-heavy queries. However, balance it since excessive indexing can slow down write operations.
> 
> üîç **Optimize Database Queries (No More Slow Queries)**
> - **Tech:** Indexing, Connection Pooling, Caching  
> - **Example:** Use Hibernate caching and JOINS efficiently to reduce query time.

##### Indexing : 
   When you create an index , the databases does preprocessing behind the scences
     to build a fast-searchable strcutrue 
   Usually a B-Tree (Like a sorted Tree) 
    What Happens when you create an index ..? 
  SQL : CREATE INDEX idx_user_status ON orders (user_Id, status);
  The Database does this unde the hood.
   1. Scans the whole table once
   2. Picks values of user_id and status
   3. Sort them 
   4. Build a tree (Like below)
                (user_id=99)
               /    \
  (user_id=50)       (user_id=150)
       |
(status='SHIPPED') ‚Üí Row IDs: 2, 8, 14

  5. Stores this in a seperate hidden storage - not part of the table
   This strucute is kept updated automatically : 
    When you INSERT or UPDATE , DB updates the index too.

Querying Later(The Magic) 
  Now eher you run : 
 Select * from orders WHERE USER_ID = 99 AND stauts ="Shipped";
   Instaed of going row by row : 
    i)   DB jumps into the tree
    ii)  Locates the matching values
    iii) Quickly grabs row IDs
    iv)  Fetehces Data

üéØ Your Question:
How does an index prevent scanning all rows in the database?

 First, Imagine a Real-World Example
üîç You have a notebook with 1,000 pages.
Someone says:

‚ÄúFind all pages where ‚ÄòKranthi Kumar‚Äô is mentioned.‚Äù

‚ùå Without Index:
You go page by page, read each word ‚Äî it takes a long time.

‚úÖ With Index:
You turn to the Index Page at the end of the book:

Kranthi Kumar ‚Üí Page 42, Page 237, Page 744

You directly go to only those pages, not all 1,000.
This is exactly what database indexing does.

üî¢ Database Without Index
Imagine this table:
| ID        | USER\_ID | STATUS  | TOTAL |
| --------- | -------- | ------- | ----- |
| 1         | 100      | SHIPPED | 500   |
| 2         | 101      | PENDING | 300   |
| 3         | 100      | SHIPPED | 700   |
| ‚Ä¶         | ‚Ä¶        | ‚Ä¶       | ‚Ä¶     |
| 1,000,000 | ‚Ä¶        | ‚Ä¶       | ‚Ä¶     |

SELECT * FROM orders WHERE user_id = 100 AND status = 'SHIPPED';

 Without index:

The DB goes row-by-row

Checks each user_id and status

All 1,000,000 rows are read

This is called a Sequential Scan ‚Äî slow.

‚úÖ With Index (Internal View)
When you create an index on (user_id, status):
CREATE INDEX idx_user_status ON orders(user_id, status);

The DB builds a tree-like structure (usually a B-Tree). Internally, it stores something like:

(user_id=100, status='SHIPPED') ‚Üí row 1, row 3, row 5007
(user_id=101, status='PENDING') ‚Üí row 2, row 88
...
Now, when you run the same query, the DB:

 i)Looks into this fast B-tree

ii)Finds only the relevant row IDs

iii)Skips scanning other rows

This is called an Index Scan ‚Äî fast!

 Visual Example in DB

    SELECT * FROM orders WHERE user_id = 100 AND status = 'SHIPPED';
 Without Index : 
  Row 1 ‚Üí Check ‚úÖ
Row 2 ‚Üí Check ‚ùå
Row 3 ‚Üí Check ‚úÖ
Row 4 ‚Üí Check ‚ùå
...
(all 1 million rows)
 With Index : 
Jump to Index Tree ‚Üí
Found (user_id=100, status='SHIPPED') ‚Üí
Row IDs: 1, 3, 5007 ‚Üí
Jump directly to those rows.
Only 3 rows read vs. 1 million.

 Summary for Interview:
‚ÄúAn index is a tree-like data structure that stores mappings of key values (like user_id, status) to row locations. 
Instead of scanning every row, the database uses the index to directly jump to matching rows, 
just like using the index in a book to find pages without reading the whole book.‚Äù


In Short :
| Without Index                     | With Index                       |
| --------------------------------- | -------------------------------- |
| Reads every row                   | Uses tree to jump directly       |
| Slow                              | Fast                             |
| Like reading every page in a book | Like jumping to page using index |

=======*********Practical about Indexing  like How to Impllment ******======:

 Hibernate / JPA + Indexing : 
Step 1: Define your entity (Order.java) 
Step 2: Add Index using @Index in @Table
Step 3: Write Repository Query : 

Step 1: Define your entity (Order.java)
@Entity
@Table(name = "orders")
public class Order {

    @Id
    @GeneratedValue
    private Long id;

    @Column(name = "user_id")
    private Long userId;

    @Column(name = "order_status")
    private String orderStatus;

    private LocalDateTime createdAt;

    private BigDecimal totalAmount;
}
 What Happens Here : 
  i) You define a class that maps to a orders table in your database
  ii) JPA/ Hibernate takes cares of mapping filed to columns

Step 2:  Add Index using @Inde in @table 
 @Entity 
@Table(name = "orders", 
         indexes = { @Index(name ="idx_user_stauts", columnList = "user_id,order_status")
                    }
      )
  public class Order {
   // same fileds 
  }

 What does @Index do ..? 
  i) It tells Hibernate to generate a CREATE INDEX DDL when it creates the schema
  ii) This only works if hibenrate is managing (i.e
    spring.jpa.hibenrate.ddl-auto= create or update).
if the table is already created, this index won't be created unless schame generation is enabled or handled manually.
  What SQL gets Generated ..? 
   Behind the scenes , Hibenate will genrate something like": 
  CREATE INDEX idx_user_staus ON orders (user_id, orde_stauts);
This create a composite index for faster filtering on boht columns

Step 3: Write Repository Query : 
  public interface OrderRepository extends JpaRepository <Order,Long> {
   List<Order> findByUserIdAndOrderStaus(Long userId, String status) ;
}
What Happens here : 
Spring Data JPA dynamically createa a method that perfomrs : 
  Select * from ordes WHERE userd_id = ? AND order_status = ? ;

Index Usage : 
 i)If the index idx_user_stauts exisint on the databases,
   databases optimizer will automatcaiily choose it when it's faster.
 ii) JPA doesn't "force" index usage - the databases query planner decides.

  iii) you can see this using : 
EXPLAIN ANALYZE SELECT * FROM orders WHERE user_id = 123 AND order_status = 'SHIPPED';

 When doed it works Best ..? 
| Query                                    | Index Used?                                              |
| ---------------------------------------- | -------------------------------------------------------- |
| `WHERE user_id = ? AND order_status = ?` | ‚úÖ Yes                                                    |
| `WHERE order_status = ? AND user_id = ?` | ‚úÖ Still Yes (order inside composite is usually flexible) |
| `WHERE user_id = ?`                      | ‚úÖ Yes (partial match)                                    |
| `WHERE order_status = ?`                 | ‚ùå No (only if it‚Äôs the first in index)                   |


  If you often filter only by order_status, then create a separate index on order_status.

 ‚öôÔ∏è Enable Schema Generation for Index to Take Effect
In your application.properties:
spring.jpa.hibernate.ddl-auto=create  # or update

OR if using Flyway or Liquibase, handle indexes there.

‚úÖ Testing Index Effectiveness (Optional but Powerful)
You can:

Insert 100,000+ records in the table.

Run the query with:
EXPLAIN ANALYZE SELECT * FROM orders WHERE user_id = 123 AND order_status = 'SHIPPED';
Note if it uses:

Index Scan ‚úÖ (Good)

Seq Scan ‚ùå (Bad)

üîÑ How to Add Index in Existing Database (Manual SQL)
If Hibernate is not generating it (because schema is frozen), just run:
CREATE INDEX idx_user_status ON orders(user_id, order_status);
‚úÖ This immediately speeds up applicable queries.

Bonus : Add Indexes for Foreign Keys Automatically : 
  IF user_id reference a users table , indexing it is good for JOINs
JPA CAN AUTO-GENERATE IT VIA :

 @ManyToOne
 @JoinColumn(name ="user_id", foreignKey = @ForeignKey(name ="fk_user"))
 private User user;
Most DBs automatically create indexes for foreign keys ‚Äî if not, add manually.

 Final Summary to Remember / Say in Interview:
‚ÄúIn Hibernate, I define composite indexes using the @Index annotation inside the @Table.
This lets Hibernate generate SQL DDL like CREATE INDEX. 
I write repository queries using Spring Data JPA which generate SQL
like SELECT * FROM orders WHERE user_id=? AND order_status=?. 
If the index exists, the database query planner will choose it for fast access. 
I verify this using EXPLAIN ANALYZE and tune index selection based on real query usage patterns.‚Äù


#### Connection pooling
    Wihout connection pooling, every DB request will : 
     i) Create a new connection .
     ii) Authenticate (TCP + DB handshake) 
     iii) Send the query 
     iv) Receive the response 
     v) Close the connection 
  This repeat -for every request flow is extremenly expensive.
  üß± Technical Problems Without Pooling
   
| Problem                              | Impact                                                                                                           |
| ------------------------------------ | ---------------------------------------------------------------------------------------------------------------- |
| **Connection creation is expensive** | TCP handshake + authentication + DB resource allocation take 100-500ms per call.                                 |
| **Resource leak risk**               | If you forget to close a connection manually, it stays open until timeout.                                       |
| **Limited DB connection limit**      | Databases like MySQL/PostgreSQL have a max connections cap (e.g., 100). You‚Äôll hit `Too many connections` error. |
| **Slow performance**                 | For high-concurrent apps, it fails under load.                                                                   |
| **No reuse**                         | Wasted effort: every connection is created & destroyed.                                                          |
| **Increased latency**                | Connection creation adds delay to every request.                                                                 |
| **Garbage collection pressure**      | Each connection object adds memory churn = more frequent GC = more CPU usage.                                    |

  üîß With Connection Pooling (like HikariCP)
   NOW cOMPARE THAT WITH POOLING : 
    i)  At app statup : 5-10 connections cretaed and stored in memory
    ii) Every request : Borrow a ready connection from the pool.
    iii) After Use : Return it to the pool, not closed 
    iv) Super fast : no handshake , no DB overload, no dealy.
üîÑ Timeline Comparison
Without Pooling (per request)
100ms - Open connection
50ms  - Run query
10ms  - Read response
50ms  - Close connection
= ~210ms total per request
With Pooling
5ms - Borrow from pool
50ms - Run query
10ms - Read response
5ms - Return to pool
= ~70ms total per request

üöÄ ~3x faster, and scales much better under load.

üö´ Without Connection Pooling (BAD WAY)
Each request opens and closes a new DB connection.
public class OrderService {
    public void placeOrder() {
        try {
            Connection connection = DriverManager.getConnection(
                "jdbc:mysql://localhost:3306/mydb", "root", "password");

            // Execute query
            PreparedStatement ps = connection.prepareStatement("INSERT INTO orders (...) VALUES (...)");
            ps.executeUpdate();

            connection.close(); // Always closing after single use
        } catch (SQLException e) {
            e.printStackTrace();
        }
    }
}
‚õî Problems:

Slow performance ‚Äì Creating a new connection takes ~100ms‚Äì500ms.

Wastes CPU/Memory ‚Äì DB and app server work extra to keep opening/closing connections.

Poor scalability ‚Äì With 1000 users, DB may die with 1000 open requests.

Exhausts DB connections ‚Äì Limited connections allowed (say 100). If all used, others fail.


‚úÖ With Connection Pooling (GOOD WAY)
Connections are reused from a ready-made pool (e.g., HikariCP, Apache DBCP).

@Configuration
public class DataSourceConfig {

    @Bean
    public DataSource dataSource() {
        HikariConfig config = new HikariConfig();
        config.setJdbcUrl("jdbc:mysql://localhost:3306/mydb");
        config.setUsername("root");
        config.setPassword("password");
        config.setMaximumPoolSize(10); // max 10 active connections
        return new HikariDataSource(config);
    }
}

Then your code just injects the datasource:
@Autowired
private DataSource dataSource;

public void placeOrder() {
    try (Connection connection = dataSource.getConnection()) {
        PreparedStatement ps = connection.prepareStatement("INSERT INTO orders (...) VALUES (...)");
        ps.executeUpdate();
    } catch (SQLException e) {
        e.printStackTrace();
    }
}

Step 1: Add to application.properties

spring.datasource.url=jdbc:mysql://localhost:3306/mydb
spring.datasource.username=root
spring.datasource.password=password

# HikariCP settings
spring.datasource.hikari.pool-name=MyHikariPool
spring.datasource.hikari.maximum-pool-size=10
spring.datasource.hikari.minimum-idle=2
spring.datasource.hikari.idle-timeout=30000
spring.datasource.hikari.connection-timeout=20000
 Step 2: Java Configuration Using @Value
import com.zaxxer.hikari.HikariConfig;
import com.zaxxer.hikari.HikariDataSource;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

import javax.sql.DataSource;

@Configuration
public class DataSourceConfig {

    @Value("${spring.datasource.url}")
    private String jdbcUrl;

    @Value("${spring.datasource.username}")
    private String username;

    @Value("${spring.datasource.password}")
    private String password;

    @Value("${spring.datasource.hikari.maximum-pool-size}")
    private int maxPoolSize;

    @Value("${spring.datasource.hikari.minimum-idle}")
    private int minIdle;

    @Value("${spring.datasource.hikari.idle-timeout}")
    private long idleTimeout;

    @Value("${spring.datasource.hikari.connection-timeout}")
    private long connectionTimeout;

    @Value("${spring.datasource.hikari.pool-name}")
    private String poolName;

    @Bean
    public DataSource dataSource() {
        HikariConfig config = new HikariConfig();
        config.setJdbcUrl(jdbcUrl);
        config.setUsername(username);
        config.setPassword(password);
        config.setMaximumPoolSize(maxPoolSize);
        config.setMinimumIdle(minIdle);
        config.setIdleTimeout(idleTimeout);
        config.setConnectionTimeout(connectionTimeout);
        config.setPoolName(poolName);
        return new HikariDataSource(config);
    }
}
@Autowired
private DataSource dataSource;

public void withPooling() throws SQLException {
    try (Connection conn = dataSource.getConnection()) {
        // Fast! Because it reuses from the pool
    }
}

‚úÖ Reuses existing connections.

‚úÖ Fast: typically <1ms.

‚úÖ Controlled number of open connections.


| Feature               | Without Pooling      | With HikariCP         |
| --------------------- | -------------------- | --------------------- |
| Connection Setup Time | Slow (500ms/request) | Fast (<1ms)           |
| Resource Usage        | High                 | Efficient             |
| Scalability           | Poor                 | Excellent             |
| Code Simplicity       | Messy                | Clean via Spring Boot |


#Caching :  
  Caching is the process of temporarily storing frequecny acccess data
   in memory (RAM) to avoid repeated slow access to undeyling system like:
     DataBases (RDBMS) 
     DiskStorage 
     APIS
Instead of hitting the database every time, 
we fetch it once and cache it for future requests.

üéØ Why is Caching Important?
Without caching:

Every request ‚Üí hits DB ‚Üí latency increases

More DB load ‚Üí expensive + slower performance

With caching:

1st request fetches from DB

Next 1000 requests get from in-memory ‚Üí ‚ö°fast response

 Simple Caching Example in Spring Boot
1Ô∏è‚É£ Add dependency in pom.xml (for Redis or Caffeine)

<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-cache</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>

 2Ô∏è‚É£ Enable Caching in Main Class
@SpringBootApplication
@EnableCaching
public class MyApp {}

3Ô∏è‚É£ Annotate Method with @Cacheable

@Service
public class ProductService {

    @Cacheable("productCache") // caches based on productId
    public Product getProductById(Long productId) {
        System.out.println("Fetching from DB...");
        return productRepository.findById(productId).orElse(null);
    }
}

‚úÖ First call ‚Üí hits DB
‚úÖ Next call ‚Üí gets from cache
‚ö†Ô∏è If productId is changed or removed ‚Üí cache updated automatically

üß™ How It Helps Performance
Let‚Äôs simulate:

| Requests | With DB Only              | With Cache                                          |
| -------- | ------------------------- | --------------------------------------------------- |
| 1000     | 1000 DB hits √ó 20ms = 20s | 1 DB hit + 999 cache hits = 20ms + (999√ó1ms) = \~1s |


üìâ 95% latency drop, 10√ó better throughput

üîÅ Other Cache Annotations:
| Annotation    | Description                                    |
| ------------- | ---------------------------------------------- |
| `@Cacheable`  | Cache the result of a method                   |
| `@CachePut`   | Updates cache without skipping method          |
| `@CacheEvict` | Remove entry from cache (manually or on event) |

 Redis Config (Optional for Distributed Cache)
spring.cache.type=redis
spring.redis.host=localhost
spring.redis.port=6379

Or configure Redis CacheManager via @Bean

üìâ What if No Caching?
Each API request ‚Üí DB hit ‚Üí adds latency

Under load ‚Üí DB gets overwhelmed

Even read-heavy systems suffer

  Type of Caches : 
1. SimpleCache (Default in Spring Boot) 
  i) Storage : In-Memory (ConcurrentHashMap) 
  ii) Eviction/Expiry : NO TTL,no Size Limits : 
  iii) Thread Safety : Yes (ConcurrentHashMap)
  iv) Persistence : No 
   v) Use When : Learning , Prototyping , small apps.
  application.propoerties : 
   
  spring.cache.type=simple

‚úÖ Pros:

No config required

Very fast (pure memory)

‚ùå Cons:

No control over eviction or TTL

Not suitable for production or large apps

üöÄ 2. Caffeine
  i) Storage: In-JVM memory (super fast)

  ii) Eviction: ‚úÖ Time-based, size-based
  iii) Thread Safety: ‚úÖ
  iv) Async Loading: ‚úÖ
 v)Use When: You need fast, configurable caching on one server (no clustering)

 spring.cache.type=caffeine
spring.cache.caffeine.spec=maximumSize=1000,expireAfterAccess=10m

4. Redis
Storage: In-memory (remote server)

Eviction: ‚úÖ TTL, LRU, LFU

Persistence: ‚úÖ (snapshot or AOF)

Use When: You want shared cache across services, horizontal scalability

spring.cache.type=redis
spring.redis.host=localhost

Pros:

Distributed cache

Language-agnostic (works outside Java too)

TTL support, pub/sub, persistence

‚ùå Cons:

Network latency (vs in-JVM)

Requires Redis setup

Might be overkill for small apps


#5) Asynchoronous Processing (Don't Block the thread) 
   Tech : CompletableFuture , Reactive Streams ,ExectiveSerive 
  Example : Use Spring WebFlux for non-blocking I/O operations.

   ##CompletableFuture : 
    Java's CompletableFuture allows you to run tasks asynchronously and non-blocking, improving throughput and response time.


  ‚úÖ Key Benefits
‚úÖ Runs tasks in parallel using ExecutorService (thread pool).

‚úÖ Frees up main thread ‚Äî avoids blocking.

‚úÖ Allows chaining and composing multiple futures (e.g. thenApply, thenCombine, thenCompose).

‚úÖ Handles errors gracefully (exceptionally, handle).


CompletableFuture<String> userFuture = CompletableFuture.supplyAsync(() -> getUserFromAPI());
CompletableFuture<List<Order>> ordersFuture = CompletableFuture.supplyAsync(() -> getOrdersFromDB());

CompletableFuture<Void> allDone = CompletableFuture.allOf(userFuture, ordersFuture);

allDone.thenRun(() -> {
    String user = userFuture.join();
    List<Order> orders = ordersFuture.join();
    display(user, orders);
});

‚ö° This will fetch user and order data in parallel, reducing latency from 2x ‚Üí 1x.

 Use Cases
API aggregations (fetch data from multiple sources).

Heavy DB or file operations.

Sending notifications / background processing.

Parallel data processing in microservices.



